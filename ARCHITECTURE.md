# ðŸ—ï¸ System Architecture

## Overview

This document describes the production ML system architecture for both portfolio projects, demonstrating scalable, fault-tolerant design principles applicable to frontier AI applications.

---

## Project 1: Breast Cancer Classification Pipeline

### Production ML Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data Input â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing Pipeline     â”‚
â”‚  â€¢ VIF Analysis             â”‚
â”‚  â€¢ SMOTE Balancing          â”‚
â”‚  â€¢ Feature Scaling          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parallel Model Training    â”‚
â”‚  â€¢ 8 Ensemble Methods       â”‚
â”‚  â€¢ Stratified 5-Fold CV     â”‚
â”‚  â€¢ Hyperparameter Tuning    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Evaluation & Selectionâ”‚
â”‚  â€¢ ROC-AUC Analysis         â”‚
â”‚  â€¢ Clinical Metrics         â”‚
â”‚  â€¢ Performance Profiling    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Production Deployment      â”‚
â”‚  â€¢ Model Persistence        â”‚
â”‚  â€¢ REST API (FastAPI)       â”‚
â”‚  â€¢ Docker Container         â”‚
â”‚  â€¢ Monitoring & Logging     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

| Principle | Implementation |
|-----------|----------------|
| **Modularity** | Each pipeline stage is independently testable |
| **Fault Tolerance** | Graceful handling of missing data, model failures |
| **Scalability** | Parallel cross-validation, efficient data structures |
| **Observability** | Comprehensive logging, performance metrics |
| **Reproducibility** | Fixed random seeds, versioned dependencies |

### API Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Load Balancer                             â”‚
â”‚                   (nginx / ALB)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           â”‚
        â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Pod 1   â”‚          â”‚   API Pod 2   â”‚
â”‚   (FastAPI)   â”‚          â”‚   (FastAPI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Model Registry                            â”‚
â”‚                   (MLflow / S3)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Project 2: LLM Ensemble Bias Detection

### Distributed LLM Ensemble Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Orchestration Layer                      â”‚
â”‚  â€¢ Rate Limiting (60 req/min per endpoint)               â”‚
â”‚  â€¢ Circuit Breakers (automatic failover)                 â”‚
â”‚  â€¢ Retry Logic (exponential backoff)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Load Balancer  â”‚      â”‚  Cache Layer    â”‚
    â”‚  (Round Robin)  â”‚      â”‚  (Redis/Memory) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Parallel Processing Pool            â”‚
    â”‚  ThreadPoolExecutor (max_workers=10)    â”‚
    â””â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚      â”‚      â”‚
   â”Œâ”€â”€â–¼â”€â”€â” â”Œâ–¼â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”
   â”‚GPT-4â”‚ â”‚Claudeâ”‚ â”‚Llamaâ”‚
   â”‚ API â”‚ â”‚ API â”‚ â”‚ API â”‚
   â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
```

### Components

#### 1. API Orchestration Layer

```python
class LLMOrchestrator:
    """Manages multi-model API calls with fault tolerance."""
    
    def __init__(self):
        self.clients = {
            'gpt4': OpenAIClient(rate_limit=60),
            'claude3': AnthropicClient(rate_limit=60),
            'llama3': TogetherClient(rate_limit=60)
        }
        self.circuit_breakers = {
            model: CircuitBreaker(failure_threshold=5)
            for model in self.clients
        }
        
    async def call_with_retry(self, model, prompt, max_retries=3):
        """Call LLM with exponential backoff retry."""
        for attempt in range(max_retries):
            try:
                if self.circuit_breakers[model].is_open():
                    raise CircuitBreakerOpen(f"{model} unavailable")
                    
                response = await self.clients[model].complete(prompt)
                self.circuit_breakers[model].record_success()
                return response
                
            except RateLimitError:
                wait_time = 2 ** attempt
                await asyncio.sleep(wait_time)
            except APIError as e:
                self.circuit_breakers[model].record_failure()
                raise
                
        raise MaxRetriesExceeded()
```

#### 2. Parallel Processing Pipeline

```python
def process_passages_parallel(passages, models, max_workers=10):
    """Process passages in parallel across all models."""
    results = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_passage = {
            executor.submit(rate_passage, passage, model): (passage, model)
            for passage in passages
            for model in models
        }
        
        for future in tqdm(as_completed(future_to_passage)):
            passage, model = future_to_passage[future]
            try:
                result = future.result(timeout=30)
                results.append(result)
            except Exception as e:
                logger.error(f"Failed: {e}")
                results.append(None)
                
    return results
```

#### 3. Bayesian Inference Engine

```python
class BayesianInferencePipeline:
    """Production Bayesian hierarchical modeling with PyMC."""
    
    def __init__(self, n_chains=4, n_iterations=2000):
        self.n_chains = n_chains
        self.n_iterations = n_iterations
        self.convergence_threshold = 1.01  # R-hat
        
    def sample_with_diagnostics(self, model):
        """Sample with comprehensive diagnostics."""
        with model:
            trace = pm.sample(
                draws=self.n_iterations,
                chains=self.n_chains,
                cores=self.n_chains,
                return_inferencedata=True
            )
            
            # Validate convergence
            rhat = az.rhat(trace)
            ess = az.ess(trace)
            self.validate_convergence(rhat, ess)
            
            return trace
```

---

## Data Flow Diagrams

### Breast Cancer Classification

```
Input Layer           Processing Layer         Output Layer
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                              
[Patient       ]     [StandardScaler  ]     [Prediction    ]
[Features (30) ] â”€â”€â–¶ [Transform       ] â”€â”€â–¶ [Probability   ]
                     [               ]     [Confidence    ]
                            â”‚
                            â–¼
                     [RFE Selector    ]
                     [15 Features     ]
                            â”‚
                            â–¼
                     [AdaBoost Model  ]
                     [99.12% Accuracy ]
```

### LLM Ensemble Bias Detection

```
Input Layer           Processing Layer         Output Layer
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[Textbook      ]     [LLM Ensemble    ]     [Bias Score    ]
[Passage       ] â”€â”€â–¶ [GPT-4, Claude,  ] â”€â”€â–¶ [Confidence    ]
[              ]     [Llama           ]     [Explanation   ]
                            â”‚
                            â–¼
                     [Aggregation     ]
                     [Krippendorff Î±  ]
                            â”‚
                            â–¼
                     [Bayesian Model  ]
                     [Publisher Effects]
```

---

## Monitoring & Observability

### Metrics Collection

```python
from prometheus_client import Counter, Histogram, Gauge

# Define metrics
prediction_counter = Counter(
    'predictions_total', 
    'Total number of predictions',
    ['model', 'prediction']
)

prediction_latency = Histogram(
    'prediction_latency_seconds',
    'Time spent processing prediction',
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]
)

model_confidence = Histogram(
    'model_confidence',
    'Prediction confidence distribution',
    buckets=[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1.0]
)
```

### Logging Configuration

```python
import structlog

logger = structlog.get_logger()
logger.info("Prediction made", extra={
    "prediction": "Benign",
    "confidence": 0.95,
    "latency_ms": 0.8,
    "model_version": "v1.0"
})
```

### Alerting Rules

| Alert | Condition | Action |
|-------|-----------|--------|
| High Error Rate | 5xx > 5% (5min) | Page on-call |
| Slow Predictions | p95 latency > 100ms | Investigate |
| Low Confidence | confidence < 0.7 rate > 10% | Review model |
| API Quota | usage > 80% daily | Scale up |

---

## Deployment Architecture

### Kubernetes Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: breast-cancer-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: breast-cancer-api
  template:
    spec:
      containers:
      - name: api
        image: breast-cancer-api:v1.0
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
```

### Production Considerations

| Aspect | Implementation |
|--------|----------------|
| **Horizontal Scaling** | Stateless API design enables load balancing |
| **Vertical Scaling** | 10x speedup through vectorization |
| **Fault Tolerance** | Automatic retry with exponential backoff |
| **Monitoring** | Prometheus metrics, structured logging |
| **Security** | Input validation, rate limiting, secrets management |

---

*Architecture documentation updated November 2025*
