# Derek Lankeaux, MS
## Research Engineer | ML Systems Architect | AI Safety Researcher

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/derek-lankeaux)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github)](https://github.com/dl1413)
[![Portfolio](https://img.shields.io/badge/Portfolio-Visit-00C7B7?style=for-the-badge)](https://dl1413.github.io/LLM-Portfolio/)
[![Email](https://img.shields.io/badge/Email-Contact-EA4335?style=for-the-badge&logo=gmail)](mailto:contact@example.com)

---

### ğŸ¯ Research Engineer | Actively Seeking 2026 Opportunities

**Specialization:** Large Language Models â€¢ Ensemble Learning â€¢ Bayesian Statistics â€¢ Production ML Systems

> **Impact-Driven Research Engineer** with expertise in multi-model LLM ensembles, Bayesian hierarchical modeling, and production ML pipelines. Proven track record of delivering **99.12% accuracy** models and processing **67.5K+ LLM API calls** at scale. Published researcher with deep expertise in statistical validation, responsible AI governance (IEEE 2830-2025), and MLOps best practices.

### ğŸ† Key Achievements

- ğŸ”¬ **Developed novel LLM ensemble framework** achieving Krippendorff's Î± = 0.84 (excellent reliability) across GPT-4o, Claude-3.5, and Llama-3.2
- ğŸ¥ **Built production ML system** for breast cancer classification with **99.12% accuracy**, exceeding human expert performance
- ğŸ“Š **Processed 2.5M+ tokens** through production-grade API pipeline with circuit breakers and adaptive rate limiting
- ğŸ“ˆ **Published 2 technical reports** demonstrating expertise in Bayesian inference, ensemble methods, and statistical rigor
- âš¡ **Deployed FastAPI models** with <100ms p95 latency and comprehensive monitoring dashboards

---

## ğŸš€ Featured Research Projects

<table>
<tr>
<td width="50%" valign="top">

### ğŸ”¬ LLM Ensemble Bias Detection
**[ğŸ“„ Technical Report](./LLM_Ensemble_Bias_Detection_Report.md)** | **[ğŸ“Š Publication](./LLM_Bias_Detection_Publication.pdf)**

**Novel multi-LLM framework for bias detection using Bayesian hierarchical modeling**

#### Impact Metrics
- ğŸ“Š **67,500 bias ratings** processed across 4,500 passages
- ğŸ¯ **Krippendorff's Î± = 0.84** (excellent inter-rater reliability)
- ğŸ“ˆ **Statistically significant findings** (Friedman Ï‡Â² = 42.73, p < 0.001)
- âš¡ **Production-scale deployment** handling 2.5M tokens

#### Technical Innovation
- **Multi-LLM Ensemble**: GPT-4o, Claude-3.5-Sonnet, Llama-3.2 with 92% pairwise correlation
- **Bayesian Inference**: PyMC hierarchical model with partial pooling, MCMC convergence (R-hat < 1.01)
- **Statistical Rigor**: 95% HDI quantification, publisher-level credible bias detection (3/5 significant)
- **Production Engineering**: Circuit breakers, exponential backoff, MLflow tracking

#### Tech Stack
`GPT-4o` `Claude-3.5` `Llama-3.2` `PyMC` `ArviZ` `MLflow` `FastAPI` `LangChain`

</td>
<td width="50%" valign="top">

### ğŸ¥ Breast Cancer ML Classification
**[ğŸ“„ Technical Report](./Breast_Cancer_Classification_Report.md)** | **[ğŸ“Š Publication](./Breast_Cancer_Classification_Publication.pdf)**

**Clinical-grade ensemble system exceeding human expert performance**

#### Impact Metrics
- ğŸ† **99.12% accuracy** (best-in-class AdaBoost)
- ğŸ’¯ **100% precision** (zero false positives)
- ğŸ¯ **98.59% recall** (minimal missed cases)
- ğŸ“ˆ **ROC-AUC: 0.9987** (near-perfect discrimination)

#### Technical Innovation
- **8-Algorithm Benchmark**: Comprehensive evaluation (RF, XGBoost, LightGBM, AdaBoost, Stacking, Voting)
- **Advanced Preprocessing**: VIF multicollinearity analysis, SMOTE balancing, RFE feature selection
- **Explainable AI**: SHAP values for clinical transparency, fairness auditing (IEEE 2830-2025)
- **Production Ready**: MLflow registry, FastAPI deployment (<100ms p95 latency)

#### Tech Stack
`scikit-learn` `XGBoost` `LightGBM` `SMOTE` `SHAP` `MLflow` `FastAPI`

</td>
</tr>
</table>

---

## ğŸ’¼ Professional Experience & Capabilities

### ğŸ¯ Core Expertise

<table>
<tr>
<td width="33%" valign="top">

#### ğŸ¤– LLM & NLP
- Multi-model ensemble architectures
- Prompt engineering & optimization
- Inter-rater reliability analysis
- API integration at scale
- Structured output generation

**Tools:** GPT-4o, Claude-3.5, Llama-3.2, HuggingFace, LangChain

</td>
<td width="33%" valign="top">

#### ğŸ“Š Statistical ML
- Ensemble methods (8+ algorithms)
- Bayesian hierarchical modeling
- MCMC diagnostics (R-hat, ESS)
- Hypothesis testing & validation
- Feature engineering & selection

**Tools:** PyMC, ArviZ, scikit-learn, XGBoost, LightGBM

</td>
<td width="33%" valign="top">

#### âš™ï¸ Production MLOps
- FastAPI model deployment
- MLflow experiment tracking
- Circuit breakers & rate limiting
- Monitoring & drift detection
- Docker/Kubernetes orchestration

**Tools:** MLflow, FastAPI, Docker, Redis, Prometheus

</td>
</tr>
</table>

### ğŸ› ï¸ Technical Stack

```yaml
Languages:        Python 3.12+ â€¢ R â€¢ SQL â€¢ Bash
ML Frameworks:    PyTorch 2.0+ â€¢ TensorFlow 2.15+ â€¢ scikit-learn 1.5+ â€¢ JAX
LLM APIs:         OpenAI (GPT-4o) â€¢ Anthropic (Claude-3.5) â€¢ Meta (Llama-3.2) â€¢ HuggingFace
Ensemble ML:      XGBoost 2.1+ â€¢ LightGBM 4.5+ â€¢ CatBoost â€¢ AdaBoost
Bayesian Stats:   PyMC 5.15+ â€¢ ArviZ 0.18+ â€¢ NumPyro â€¢ Stan â€¢ JAGS
Data Stack:       Pandas 2.2+ â€¢ Polars 1.0+ â€¢ NumPy 2.0+ â€¢ Dask â€¢ Apache Arrow
MLOps:            MLflow 2.15+ â€¢ Weights & Biases â€¢ DVC â€¢ Kubeflow
Deployment:       FastAPI 0.110+ â€¢ Docker â€¢ Kubernetes â€¢ AWS â€¢ GCP
Monitoring:       Prometheus â€¢ Grafana â€¢ ELK Stack â€¢ Datadog
Explainability:   SHAP â€¢ LIME â€¢ Captum â€¢ InterpretML
Version Control:  Git â€¢ GitHub Actions â€¢ GitLab CI/CD
```

### ğŸ”¬ Research Methodology

**Statistical Rigor**
- âœ… Cross-validation (k-fold, stratified, leave-one-out)
- âœ… Bayesian inference with credible intervals (95% HDI)
- âœ… Multiple testing correction (Bonferroni, FDR, Holm-Sidak)
- âœ… Effect size reporting (Cohen's d, Î·Â², Cramer's V)
- âœ… Power analysis and sample size determination

**Reproducibility Standards**
- âœ… IEEE 2830-2025 (Transparent ML) compliance
- âœ… ISO/IEC 23894:2025 (AI Risk Management) alignment
- âœ… Fixed random seeds and version pinning
- âœ… Comprehensive model cards and documentation
- âœ… Carbon footprint tracking and reporting

**Production Engineering**
- âœ… Robust error handling and circuit breakers
- âœ… Adaptive rate limiting and backoff strategies
- âœ… Comprehensive logging (structlog) and monitoring
- âœ… A/B testing frameworks and gradual rollouts
- âœ… Model performance tracking and drift detection

---

## ğŸ“Š Quantitative Performance Summary

<table>
<tr>
<td width="50%" valign="top">

### LLM Ensemble Bias Detection
| Metric | Value | Benchmark |
|--------|-------|-----------|
| **Inter-Rater Reliability** | Î± = 0.84 | Excellent (â‰¥0.80) |
| **Model Convergence** | R-hat < 1.01 | Perfect |
| **Statistical Power** | Ï‡Â² = 42.73 | p < 0.001 |
| **Scale Deployment** | 67.5K calls | Production |
| **Credible Findings** | 3/5 publishers | 60% detection |

</td>
<td width="50%" valign="top">

### Breast Cancer Classification
| Metric | Value | Benchmark |
|--------|-------|-----------|
| **Accuracy** | 99.12% | Exceeds human (90-95%) |
| **Precision** | 100.00% | Zero false positives |
| **Recall** | 98.59% | Minimal misses |
| **ROC-AUC** | 0.9987 | Near-perfect |
| **CV Stability** | 98.46% Â± 1.12% | Robust |

</td>
</tr>
</table>

---

## ğŸ“ Education & Certifications

**Master of Science in Applied Statistics**  
Rochester Institute of Technology | Expected 2026  
*Specialization: Bayesian Methods, Machine Learning, Experimental Design*

**Relevant Coursework:**
- Advanced Bayesian Inference & MCMC Methods
- Deep Learning & Neural Networks
- Statistical Learning Theory
- Experimental Design & Causal Inference
- High-Dimensional Statistics
- Computational Statistics & Optimization

---

## ğŸ’¼ Target Opportunities (2026)

### ğŸ¯ Ideal Roles

<table>
<tr>
<td width="50%">

**Research Engineer**
- LLM evaluation & benchmarking
- Multi-model ensemble systems
- AI safety & alignment
- Model reliability assessment

</td>
<td width="50%">

**ML Systems Engineer**
- Production ML pipelines
- MLOps infrastructure
- Model deployment & monitoring
- Scalable inference systems

</td>
</tr>
<tr>
<td width="50%">

**Applied Research Scientist**
- Bayesian statistical methods
- Ensemble learning research
- Causal inference
- Experimental design

</td>
<td width="50%">

**AI Safety Researcher**
- Responsible AI governance
- Model explainability (XAI)
- Fairness & bias detection
- Compliance frameworks

</td>
</tr>
</table>

### ğŸŒŸ What I Bring

âœ… **Technical Depth**: Deep expertise in LLMs, Bayesian methods, and ensemble ML  
âœ… **Production Experience**: Deployed FastAPI models with <100ms latency at scale  
âœ… **Research Rigor**: Published work with strong statistical validation (p < 0.001)  
âœ… **AI Governance**: IEEE 2830-2025 and ISO/IEC 23894:2025 compliance experience  
âœ… **Reproducibility**: MLflow tracking, version control, comprehensive documentation  
âœ… **Impact Focus**: Track record of exceeding benchmarks (99.12% vs 90-95% human)

---

## ğŸ“š Publications & Technical Reports

| Title | Type | Date | Links |
|-------|------|------|-------|
| **LLM Ensemble Textbook Bias Detection** | Technical Report v3.0.0 | Jan 2026 | [Report](./LLM_Ensemble_Bias_Detection_Report.md) â€¢ [PDF](./LLM_Bias_Detection_Publication.pdf) |
| **Breast Cancer Classification** | Technical Report v3.0.0 | Jan 2026 | [Report](./Breast_Cancer_Classification_Report.md) â€¢ [PDF](./Breast_Cancer_Classification_Publication.pdf) |

---

## ğŸ“« Let's Connect

<div align="center">

### ğŸ¤ Open to Research Engineer Opportunities | Available for Interviews

**Preferred Contact:** [LinkedIn](https://linkedin.com/in/derek-lankeaux) | [Email](mailto:contact@example.com)

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Derek_Lankeaux-0077B5?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/derek-lankeaux)
[![GitHub](https://img.shields.io/badge/GitHub-@dl1413-181717?style=for-the-badge&logo=github)](https://github.com/dl1413)
[![Portfolio](https://img.shields.io/badge/Portfolio-Live_Site-00C7B7?style=for-the-badge)](https://dl1413.github.io/LLM-Portfolio/)

**Location:** Available for remote/hybrid positions  
**Timeline:** Seeking positions starting 2026  
**Visa Status:** Authorized to work in the United States

</div>

---

<div align="center">

## ğŸ› ï¸ Repository Structure

```
LLM-Portfolio/
â”œâ”€â”€ ğŸ“„ README.md                                      # This portfolio
â”œâ”€â”€ ğŸŒ index.html                                     # Interactive portfolio site
â”œâ”€â”€ ğŸ¨ styles.css                                     # Portfolio styling
â”œâ”€â”€ ğŸ“Š Breast_Cancer_Classification_Report.md         # ML technical report
â”œâ”€â”€ ğŸ“‘ Breast_Cancer_Classification_Publication.pdf   # Publication PDF
â”œâ”€â”€ ğŸ”¬ LLM_Ensemble_Bias_Detection_Report.md          # LLM research report
â”œâ”€â”€ ğŸ“‘ LLM_Bias_Detection_Publication.pdf             # Publication PDF
â””â”€â”€ ğŸ“ reports/                                       # Additional documentation
```

---

### ğŸ” Keywords for Search & ATS

</div>

**Machine Learning:** Deep Learning â€¢ Neural Networks â€¢ Ensemble Methods â€¢ Random Forest â€¢ XGBoost â€¢ LightGBM â€¢ AdaBoost â€¢ Gradient Boosting â€¢ Stacking â€¢ Bagging

**Large Language Models:** GPT-4 â€¢ GPT-4o â€¢ Claude-3.5-Sonnet â€¢ Llama-3.2 â€¢ BERT â€¢ Transformers â€¢ Prompt Engineering â€¢ Few-Shot Learning â€¢ Zero-Shot Learning â€¢ In-Context Learning

**Bayesian Statistics:** Hierarchical Modeling â€¢ MCMC â€¢ PyMC â€¢ Stan â€¢ Posterior Inference â€¢ Prior Specification â€¢ Credible Intervals â€¢ Bayesian Inference â€¢ Probabilistic Programming

**Statistical Methods:** Hypothesis Testing â€¢ Cross-Validation â€¢ Bootstrap â€¢ Permutation Testing â€¢ Effect Sizes â€¢ Power Analysis â€¢ Multiple Testing Correction â€¢ Inter-Rater Reliability â€¢ Krippendorff's Alpha â€¢ Cohen's Kappa

**Explainable AI (XAI):** SHAP â€¢ LIME â€¢ Feature Importance â€¢ Model Interpretability â€¢ Fairness Auditing â€¢ Bias Detection â€¢ Responsible AI â€¢ AI Ethics â€¢ AI Governance

**MLOps & Production:** MLflow â€¢ Weights & Biases â€¢ Model Registry â€¢ Experiment Tracking â€¢ FastAPI â€¢ Docker â€¢ Kubernetes â€¢ CI/CD â€¢ Model Monitoring â€¢ Drift Detection â€¢ A/B Testing

**Programming:** Python â€¢ R â€¢ SQL â€¢ PyTorch â€¢ TensorFlow â€¢ scikit-learn â€¢ Pandas â€¢ NumPy â€¢ Dask â€¢ Apache Spark

**Research Engineering:** Technical Writing â€¢ Statistical Validation â€¢ Reproducible Research â€¢ Peer Review â€¢ Literature Review â€¢ Experimental Design â€¢ Causal Inference

**AI Safety:** Model Evaluation â€¢ Benchmark Development â€¢ Reliability Assessment â€¢ Safety Testing â€¢ Alignment â€¢ Constitutional AI â€¢ Red Teaming

**Standards & Compliance:** IEEE 2830-2025 â€¢ ISO/IEC 23894:2025 â€¢ EU AI Act â€¢ GDPR â€¢ Model Cards â€¢ Transparency â€¢ Accountability

---

<div align="center">

**ğŸ“Œ Last Updated:** December 2025  
**âœ… Compliance:** IEEE 2830-2025 (Transparent ML) â€¢ ISO/IEC 23894:2025 (AI Risk Management)  
**ğŸ”’ License:** Portfolio content Â© 2025 Derek Lankeaux. Code samples available under MIT License.

---

*â­ If you find this work interesting, please star this repository!*

</div>
