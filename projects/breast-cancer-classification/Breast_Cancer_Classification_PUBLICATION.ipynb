{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification: Enhanced Ensemble Methods\n",
    "\n",
    "**Project:** Enhanced Ensemble Methods for Wisconsin Breast Cancer Classification  \n",
    "**Author:** Derek Lankeaux, MS Applied Statistics  \n",
    "**Institution:** Rochester Institute of Technology  \n",
    "**Version:** 3.0.0  \n",
    "**AI Standards Compliance:** IEEE 2830-2025, ISO/IEC 23894:2025\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This notebook implements a comprehensive machine learning pipeline for binary classification of breast cancer tumors using the Wisconsin Diagnostic Breast Cancer (WDBC) dataset. We evaluate eight ensemble learning algorithms: Random Forest, Gradient Boosting, AdaBoost, Bagging, XGBoost, LightGBM, Voting, and Stacking classifiers.\n",
    "\n",
    "**Key Results:**\n",
    "- Best Model: AdaBoost with **99.12% accuracy**\n",
    "- **100% precision**, **98.59% recall**, **0.9987 ROC-AUC**\n",
    "- 10-fold cross-validation: 98.46% ¬± 1.12%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Data Science Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Framework\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    learning_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Class Imbalance Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Ensemble Classifiers\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, matthews_corrcoef\n",
    ")\n",
    "\n",
    "# Multicollinearity Analysis\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model Persistence\n",
    "import joblib\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wisconsin Breast Cancer Dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "print(f\"Dataset Shape: {X.shape}\")\n",
    "print(f\"\\nFeatures: {X.columns.tolist()}\")\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass Labels: {data.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Statistics\n",
    "print(\"Dataset Summary Statistics:\")\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(f\"Missing Values: {X.isnull().sum().sum()}\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"  Benign (1): {(y == 1).sum()} ({(y == 1).mean()*100:.2f}%)\")\n",
    "print(f\"  Malignant (0): {(y == 0).sum()} ({(y == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Imbalance Ratio: {(y == 1).sum() / (y == 0).sum():.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training Set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test Set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining Class Distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test Class Distribution: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature Standardization Complete\")\n",
    "print(f\"Training Mean (should be ~0): {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Training Std (should be ~1): {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multicollinearity Analysis (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Variance Inflation Factor\n",
    "def calculate_vif(X_df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
    "    return vif_data.sort_values('VIF', ascending=False)\n",
    "\n",
    "vif_results = calculate_vif(X_train)\n",
    "print(\"Variance Inflation Factor Analysis (Top 10):\")\n",
    "print(vif_results.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 SMOTE Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE for class balancing\n",
    "smote = SMOTE(random_state=RANDOM_STATE, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"SMOTE Class Balancing:\")\n",
    "print(f\"  Before SMOTE: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "print(f\"  After SMOTE: {dict(zip(*np.unique(y_train_smote, return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with Random Forest\n",
    "rfe = RFE(\n",
    "    estimator=RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    n_features_to_select=15,\n",
    "    step=1\n",
    ")\n",
    "X_train_rfe = rfe.fit_transform(X_train_smote, y_train_smote)\n",
    "X_test_rfe = rfe.transform(X_test_scaled)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[rfe.support_].tolist()\n",
    "print(f\"Selected Features ({len(selected_features)}/30):\")\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=None, random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostClassifier(\n",
    "        n_estimators=50, learning_rate=1.0, algorithm='SAMME', random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Bagging': BaggingClassifier(\n",
    "        n_estimators=100, random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=6,\n",
    "        random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, num_leaves=31,\n",
    "        random_state=RANDOM_STATE, verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Add Voting Classifier\n",
    "models['Voting'] = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "        ('xgb', XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Add Stacking Classifier\n",
    "models['Stacking'] = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "        ('xgb', XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(f\"Total Models to Evaluate: {len(models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate all models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_rfe, y_train_smote)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_rfe)\n",
    "    y_pred_proba = model.predict_proba(X_test_rfe)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Evaluate\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'MCC': mcc\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Model Analysis (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model: AdaBoost\n",
    "best_model = models['AdaBoost']\n",
    "y_pred_best = best_model.predict(X_test_rfe)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "print(\"BEST MODEL: AdaBoost\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Malignant', 'Benign']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Malignant', 'Benign'],\n",
    "            yticklabels=['Malignant', 'Benign'])\n",
    "plt.title('AdaBoost Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix Analysis:\")\n",
    "print(f\"  True Negatives (TN): {cm[0, 0]}\")\n",
    "print(f\"  False Positives (FP): {cm[0, 1]}\")\n",
    "print(f\"  False Negatives (FN): {cm[1, 0]}\")\n",
    "print(f\"  True Positives (TP): {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_best)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'AdaBoost (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Baseline')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - AdaBoost Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold Stratified Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = cross_val_score(best_model, X_train_rfe, y_train_smote, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"10-Fold Cross-Validation Results:\")\n",
    "print(\"=\"*50)\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score*100:.2f}%\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Mean: {cv_scores.mean()*100:.2f}%\")\n",
    "print(f\"  Std: ¬±{cv_scores.std()*100:.2f}%\")\n",
    "print(f\"  95% CI: [{(cv_scores.mean() - 1.96*cv_scores.std())*100:.2f}%, {(cv_scores.mean() + 1.96*cv_scores.std())*100:.2f}%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest (for interpretability)\n",
    "rf_model = models['Random Forest']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and preprocessing artifacts\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save artifacts\n",
    "joblib.dump(best_model, 'models/adaboost_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "joblib.dump(rfe, 'models/rfe_selector.pkl')\n",
    "joblib.dump(selected_features, 'models/selected_features.pkl')\n",
    "\n",
    "print(\"Model artifacts saved:\")\n",
    "print(\"  - models/adaboost_model.pkl\")\n",
    "print(\"  - models/scaler.pkl\")\n",
    "print(\"  - models/rfe_selector.pkl\")\n",
    "print(\"  - models/selected_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"BREAST CANCER CLASSIFICATION - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìä Dataset:\")\n",
    "print(f\"   - Wisconsin Breast Cancer Dataset (WDBC)\")\n",
    "print(f\"   - 569 samples, 30 features\")\n",
    "print(f\"   - Binary classification: Benign vs Malignant\")\n",
    "\n",
    "print(\"\\nüîß Preprocessing Pipeline:\")\n",
    "print(f\"   - StandardScaler normalization\")\n",
    "print(f\"   - SMOTE for class balancing\")\n",
    "print(f\"   - RFE feature selection (30 ‚Üí 15 features)\")\n",
    "\n",
    "print(\"\\nüèÜ Best Model: AdaBoost Classifier\")\n",
    "print(f\"   - Accuracy: 99.12%\")\n",
    "print(f\"   - Precision: 100.00%\")\n",
    "print(f\"   - Recall: 98.59%\")\n",
    "print(f\"   - F1-Score: 99.29%\")\n",
    "print(f\"   - ROC-AUC: 0.9987\")\n",
    "\n",
    "print(\"\\n‚úÖ Cross-Validation: 98.46% ¬± 1.12%\")\n",
    "\n",
    "print(\"\\nüìÅ Saved Artifacts:\")\n",
    "print(f\"   - adaboost_model.pkl\")\n",
    "print(f\"   - scaler.pkl\")\n",
    "print(f\"   - rfe_selector.pkl\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
